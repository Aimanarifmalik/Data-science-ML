{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Intermediate Python I1. Modular Code:\n",
    "   - Write Python functions to modularize your code for data cleaning, feature engineering, and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error preparing data: \"['target'] not found in axis\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    try:\n",
    "        data=pd.read_csv('train.csv')  \n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(\"error loading data: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def clean_data(data):\n",
    "    try:\n",
    "        data=data.dropna()  # Drop rows with missing values\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(\"error cleaning data: {e}\")\n",
    "        return 0\n",
    "\n",
    "#function to prepare features and target\n",
    "def prepare_data(data):\n",
    "    try:\n",
    "        X = data.drop('target', axis=1)  # Features\n",
    "        y = data['target']  # Target\n",
    "        return X, y\n",
    "    except KeyError as e:\n",
    "        print(f\"Error preparing data: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(X_train, y_train):\n",
    "    try:\n",
    "        model=RandomForestClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error training model: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    try:\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(\"Model accuracy: {accuracy:.2f}\")\n",
    "    except Exception as e:\n",
    "        print(\"error evaluating model: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = load_data()\n",
    "    if data is not None:\n",
    "        data = clean_data(data)\n",
    "        if data is not None:\n",
    "            X, y = prepare_data(data)\n",
    "            if X is not None and y is not None:\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "                model = train_model(X_train, y_train)\n",
    "                if model is not None:\n",
    "                    evaluate_model(model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. List Comprehensions and Lambda Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squared numbers: {squared_numbers}\n",
      "Even numbers: {even_numbers}\n"
     ]
    }
   ],
   "source": [
    "numbers=[9,3,5,6,78,4]\n",
    "squared_numbers = [x**2 for x in numbers]\n",
    "print(\"Squared numbers: {squared_numbers}\")\n",
    "#lambda function to filter out even numbers\n",
    "even_numbers = list(filter(lambda x: x % 2 == 0, numbers))\n",
    "print(\"Even numbers: {even_numbers}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intermediate Python II1. Advanced Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique numbers:  {1, 98, 3, 45.87, 54}\n",
      "Union: {1, 2, 3, 4, 5, 6}\n",
      "Intersection: {3, 4}\n",
      "Difference:  {1, 2}\n"
     ]
    }
   ],
   "source": [
    "numbers=[3,1,98,54,45.87]\n",
    "\n",
    "#convert list to set to get unique elements\n",
    "unique_numbers = set(numbers)\n",
    "print(\"Unique numbers: \",unique_numbers)\n",
    "\n",
    "#set operations\n",
    "set1={1, 2, 3, 4}\n",
    "set2={3, 4, 5, 6}\n",
    "\n",
    "# Union of sets\n",
    "union_set=set1 |set2\n",
    "print(\"Union:\",union_set)\n",
    "\n",
    "# Intersection of sets\n",
    "intersection_set=set1&set2\n",
    "print(f\"Intersection:\",intersection_set)\n",
    "\n",
    "#Difference of sets\n",
    "difference_set=set1 - set2\n",
    "print(\"Difference: \",difference_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word counts {'apple': 2, 'banana': 3, 'orange': 1}\n",
      "Name: Alice\n",
      "Age: 25\n",
      "Updated data:  {'name': 'Alice', 'age': 25, 'city': 'Wonderland', 'occupation': 'Adventurer'}\n",
      "Data after deletion: {'name': 'Alice', 'age': 25, 'occupation': 'Adventurer'}\n"
     ]
    }
   ],
   "source": [
    "words=['apple','banana','apple', 'orange', 'banana', 'banana']\n",
    "#counting occurrences using a dictionary\n",
    "word_count = {}\n",
    "for word in words:\n",
    "    if word in word_count:\n",
    "        word_count[word] += 1\n",
    "    else:\n",
    "        word_count[word] = 1\n",
    "print(\"Word counts\",word_count)\n",
    "\n",
    "#dictionary operations\n",
    "data = {'name': 'Alice', 'age': 25, 'city': 'Wonderland'}\n",
    "#name is key and 25 is value allover known as keyvalues\n",
    "#accessing values\n",
    "print(\"Name:\",data['name'])\n",
    "print(\"Age:\",data['age'])\n",
    "\n",
    "#adding a new key-value pair\n",
    "data['occupation'] = 'Adventurer'\n",
    "print(\"Updated data: \",data)\n",
    "\n",
    "#removing a key-value pair\n",
    "del data['city']\n",
    "print(\"Data after deletion:\",data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First element: {my_tuple[0]}\n",
      "Last element: {my_tuple[-1]}\n",
      "Elements from index 1 to 3: {my_tuple[1:4]}\n",
      "First element of nested tuple: 1\n",
      "Second element of nested tuple: (2, 3)\n",
      "Element within a nested tuple: 5\n"
     ]
    }
   ],
   "source": [
    "#creating a tuple\n",
    "my_tuple=(1, 2, 3, 'apple','cake')\n",
    "\n",
    "#accessing elements by index\n",
    "print(\"First element: {my_tuple[0]}\")\n",
    "print(\"Last element: {my_tuple[-1]}\")\n",
    "\n",
    "#slicing tuples\n",
    "print(\"Elements from index 1 to 3: {my_tuple[1:4]}\")\n",
    "\n",
    "#nested tuple\n",
    "nested_tuple=(1, (2, 3), (4, (5, 6)))\n",
    "\n",
    "#accessing elements in a nested tuple\n",
    "print(f\"First element of nested tuple: {nested_tuple[0]}\")\n",
    "print(f\"Second element of nested tuple: {nested_tuple[1]}\")\n",
    "print(f\"Element within a nested tuple: {nested_tuple[2][1][0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lits in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List after append: [1, 2, 3, 'apple', 'banana', 'orange']\n",
      "Removed item:  orange\n",
      "List after pop: [1, 2, 3, 'apple', 'banana']\n",
      "List after extend: [1, 2, 3, 'apple', 'banana', 'grape', 'kiwi']\n",
      "Original list: [1, 2, 3, 'apple', 'banana', 'grape', 'kiwi']\n",
      "Sorted list:  [1, 2, 4, 5, 9]\n"
     ]
    }
   ],
   "source": [
    "my_list=[1, 2, 3, 'apple', 'banana']\n",
    "#Adding an element to the end of the list\n",
    "my_list.append('orange')\n",
    "print(\"List after append:\",my_list)\n",
    "last_item=my_list.pop()\n",
    "print(\"Removed item: \",last_item)\n",
    "print(\"List after pop:\",my_list)\n",
    "#extending the list with another list\n",
    "my_list.extend(['grape', 'kiwi'])\n",
    "print(\"List after extend:\",my_list)\n",
    "\n",
    "print(\"Original list:\",my_list)\n",
    "# Sorting the list will on all integers or all strings\n",
    "numbers=[4, 2, 9, 1, 5]\n",
    "numbers.sort()\n",
    "print(\"Sorted list: \",numbers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Using multiprocessing Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both processes have finished execution.\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "\n",
    "def print_numbers():\n",
    "    for i in range(5):\n",
    "        time.sleep(1)  # Simulating a time-consuming task\n",
    "        print(f\"Number: {i}\")\n",
    "\n",
    "# Create processes\n",
    "process1=multiprocessing.Process(target=print_numbers)\n",
    "process2=multiprocessing.Process(target=print_numbers)\n",
    "\n",
    "#start processes\n",
    "process1.start()\n",
    "process2.start()\n",
    "\n",
    "#wait for processes to complete\n",
    "process1.join()\n",
    "process2.join()\n",
    "\n",
    "print(\"Both processes have finished execution.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class BasicMLPipeline:\n",
    "    def __init__(self, data, target_column):\n",
    "        self.data=data\n",
    "        self.target_column=target_column\n",
    "        self.model=None\n",
    "        self.X_train=None\n",
    "        self.X_test=None\n",
    "        self.y_train=None\n",
    "        self.y_test=None\n",
    "\n",
    "    def clean_data(self):\n",
    "        #Drop rows with missing values\n",
    "        self.data=self.data.dropna()\n",
    "        print(\"Data cleaned.\")\n",
    "\n",
    "    def prepare_data(self):\n",
    "        #Aimining variables & preparing different features\n",
    "        X=self.data.drop(self.target_column, axis=1)\n",
    "        y=self.data[self.target_column]\n",
    "        return X, y\n",
    "\n",
    "    def split_data(self):\n",
    "        #Divide the given data into sets of training and test\n",
    "        X, y=self.prepare_data()\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test=train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        print(\"Data split into training and test sets.\")\n",
    "\n",
    "    def scale_features(self):\n",
    "        #Standardizing various features\n",
    "        scaler=StandardScaler()\n",
    "        self.X_train=scaler.fit_transform(self.X_train)\n",
    "        self.X_test=scaler.transform(self.X_test)\n",
    "        print(\"Features are scaled.\")\n",
    "\n",
    "    def train_model(self):\n",
    "        #Training model of RandomForestClassifier\n",
    "        self.model=RandomForestClassifier()\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        print(\"Model is now trained.\")\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        #Evaluating this model on the give testing set\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Unfortunately, model is not trained,Now Call the 'train_model' first\")\n",
    "        y_pred=self.model.predict(self.X_test)\n",
    "        accuracy=accuracy_score(self.y_test, y_pred)\n",
    "        print(\"Model's accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    def run_pipeline(self):\n",
    "        #Now running the whole pipeline\n",
    "        self.clean_data()\n",
    "        self.split_data()\n",
    "        self.scale_features()\n",
    "        self.train_model()\n",
    "        self.evaluate_model()\n",
    "\n",
    "        #Example usage\n",
    "if __name__==\"___main___\":\n",
    "    \n",
    "    data=pd.read_csv('test.csv')\n",
    "\n",
    "    #Initializing and running the pipeline\n",
    "    pipeline=BasicMLPipeline(data, target_column='target')\n",
    "    pipeline.run_pipeline()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
